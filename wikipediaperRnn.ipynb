{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16HtWiWfMeRs_Mn5zwenWmNHfe5UA74cT",
      "authorship_tag": "ABX9TyNOhm/sXAgPEFjOCunYlBu/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanaaria/Ann/blob/main/wikipediaperRnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "cM-VAHYU9tGz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6zfFV39VWQ7",
        "outputId": "dd39c1b5-fd84-40bc-cf4b-ab61244db82c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Persian-WikiText-1.txt/wikipediaperRnn.txt', 'r') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "sCutsZSBqsHc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[:1000]"
      ],
      "metadata": {
        "id": "_cPdsTkhrBoC",
        "outputId": "87a7dda1-0ee7-476d-dd47-86ac2b758903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeffعنوان مقاله: صفحهٔ اصلی\\n\\n\\n<templatestyles src=\"صفحه اصلی/\\n\\n\\n\\n\\n\\n\\nعنوان مقاله: ویکی پدیا\\n\\n\\nویکی پدیا (کوته نوشت به صورت «وپ» و «WP») یک دانشنامه برخط چندزبانه مبتنی بر وب با محتوای آزاد و همکاری باز است که با همکاری افراد داوطلب نوشته می شود و هر کسی که به اینترنت و وب دسترسی داشته باشد می تواند مقالات آن را ببیند و ویرایش کند. نام ویکی پدیا واژه ای ترکیبی است که از واژه های ویکی (وبگاه مشارکتی) و اِنسایکلوپدیا (Encyclopedia) (دانشنامه یا دائرةالمعارف) گرفته شده است. هدف ویکی پدیا آفرینش و انتشار جهانی یک دانشنامه با محتوای آزاد به تمامی زبان های زندهٔ دنیا است.\\n\\n\\nویکی پدیای انگلیسی در تاریخ ۱۵ ژانویه ۲۰۰۱ (۲۶ دی ۱۳۷۹) به صورت مکملی برای دانشنامهٔ تخصصی نیوپدیا نوشته شد. بنیان گذاران آن «جیمی ویلز» و «لری سنگر» هستند. هم اکنون بنیاد غیرانتفاعی ویکی مدیا پروژهٔ ویکی پدیا را پشتیبانی می کند. میزبان های اینترنتی اصلی این وبگاه در شهر تامپای فلوریدا هستند. همچنین میزبان های اضافی دیگری هم در شهرهای آمستردام و سئول به این وبگاه یاری می رسانند.\\n\\n\\n\"ویکی پدیا\" از پایان آوریل ۲۰۰۷ تا اکتبر ۲۰۱۹،'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = tuple(set(text))\n",
        "int2char = dict(enumerate(chars))\n",
        "char2int = {ch: ii for ii, ch in int2char.items()}\n",
        "encoded = np.array([char2int[ch] for ch in text])"
      ],
      "metadata": {
        "id": "_1FpwzXzrKBe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(arr, n_labels):\n",
        "    \n",
        "   \n",
        "    one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
        "    \n",
        "  \n",
        "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
        "    \n",
        " \n",
        "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
        "    \n",
        "    return one_hot"
      ],
      "metadata": {
        "id": "ik3_2w5mrQtE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_seq = np.array([[0, 5, 1]])\n",
        "one_hot = one_hot_encode(test_seq, 8)\n",
        "print(one_hot)"
      ],
      "metadata": {
        "id": "ISDw0PuarQ4O",
        "outputId": "f44c48b9-8bc8-4526-d23f-ed02f022e2bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batches(arr, batch_size, seq_length):\n",
        "    '''Create a generator that returns batches of size\n",
        "       batch_size x seq_length from arr.\n",
        "       \n",
        "       Arguments\n",
        "       ---------\n",
        "       arr: Array you want to make batches from\n",
        "       batch_size: Batch size, the number of sequences per batch\n",
        "       seq_length: Number of encoded chars in a sequence\n",
        "    '''\n",
        "    \n",
        "    batch_size_total = batch_size * seq_length\n",
        "   \n",
        "    n_batches = len(arr)//batch_size_total\n",
        "    \n",
        "    arr = arr[:n_batches * batch_size_total]\n",
        "   \n",
        "    arr = arr.reshape((batch_size, -1))\n",
        "    \n",
        "    \n",
        "    for n in range(0, arr.shape[1], seq_length):\n",
        "        \n",
        "        x = arr[:, n:n+seq_length]\n",
        "       \n",
        "        y = np.zeros_like(x)\n",
        "        try:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
        "        except IndexError:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "        yield x, y"
      ],
      "metadata": {
        "id": "ujJikOe8rQ7c"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU!')\n",
        "else: \n",
        "    print('No GPU available, training on CPU; consider making n_epochs very small.')\n",
        "    "
      ],
      "metadata": {
        "id": "T0-oMLQcsbH6",
        "outputId": "b20a059d-17b9-4124-c91c-ff431f720543",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharRNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
        "                               drop_prob=0.5, lr=0.001):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.lr = lr\n",
        "        \n",
        "      \n",
        "        self.chars = tokens\n",
        "        self.int2char = dict(enumerate(self.chars))\n",
        "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
        "        \n",
        "      \n",
        "        self.lstm=nn.LSTM(len(self.chars),n_hidden,n_layers,\n",
        "                          dropout=drop_prob,batch_first=True)\n",
        "        \n",
        "        \n",
        "        self.dropout=nn.Dropout(drop_prob)\n",
        "        \n",
        "       \n",
        "        self.fc=nn.Linear(n_hidden,len(self.chars))\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        ''' Forward pass through the network. \n",
        "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
        "        \n",
        "        r_output, hidden = self.lstm(x, hidden)\n",
        "        \n",
        "       \n",
        "        out = self.dropout(r_output)\n",
        "        \n",
        "      \n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "        \n",
        "      \n",
        "        out = self.fc(out)\n",
        "        return out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "       \n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "metadata": {
        "id": "YUOzP3PZrQ-z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
        "  \n",
        "    net.train()\n",
        "    \n",
        "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    \n",
        "    val_idx = int(len(data)*(1-val_frac))\n",
        "    data, val_data = data[:val_idx], data[val_idx:]\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    \n",
        "    counter = 0\n",
        "    n_chars = len(net.chars)\n",
        "    for e in range(epochs):\n",
        "      \n",
        "        h = net.init_hidden(batch_size)\n",
        "        \n",
        "        for x, y in get_batches(data, batch_size, seq_length):\n",
        "            counter += 1\n",
        "            \n",
        "          \n",
        "            x = one_hot_encode(x, n_chars)\n",
        "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "            \n",
        "            if(train_on_gpu):\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            \n",
        "            h = tuple([each.data for each in h])\n",
        "           \n",
        "            net.zero_grad()\n",
        "            \n",
        "        \n",
        "            output, h = net(inputs, h)\n",
        "            \n",
        "           \n",
        "            loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
        "            loss.backward()\n",
        "           \n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "            opt.step()\n",
        "            \n",
        "           \n",
        "            if counter % print_every == 0:\n",
        "                \n",
        "                val_h = net.init_hidden(batch_size)\n",
        "                val_losses = []\n",
        "                net.eval()\n",
        "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
        "                    \n",
        "                    x = one_hot_encode(x, n_chars)\n",
        "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "                    \n",
        "                  \n",
        "                    val_h = tuple([each.data for each in val_h])\n",
        "                    \n",
        "                    inputs, targets = x, y\n",
        "                    if(train_on_gpu):\n",
        "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "                    output, val_h = net(inputs, val_h)\n",
        "                    val_loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
        "                \n",
        "                    val_losses.append(val_loss.item())\n",
        "                \n",
        "                net.train() \n",
        "                \n",
        "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                      \"Step: {}...\".format(counter),\n",
        "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
        "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
      ],
      "metadata": {
        "id": "N4F4wJYnrRA3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_hidden = 512\n",
        "n_layers = 2\n",
        "net = CharRNN(chars, n_hidden, n_layers)\n",
        "print(net)\n",
        "batch_size = 64\n",
        "seq_length = 100\n",
        "n_epochs =  10\n",
        "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=100)"
      ],
      "metadata": {
        "id": "DyN2SE5ar2EJ",
        "outputId": "f2e9ac35-06bc-430a-d8dd-4c723d3db7da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CharRNN(\n",
            "  (lstm): LSTM(205, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=205, bias=True)\n",
            ")\n",
            "Epoch: 1/10... Step: 100... Loss: 3.1098... Val Loss: 3.0440\n",
            "Epoch: 2/10... Step: 200... Loss: 2.9608... Val Loss: 2.8706\n",
            "Epoch: 3/10... Step: 300... Loss: 2.6800... Val Loss: 2.6792\n",
            "Epoch: 4/10... Step: 400... Loss: 2.5469... Val Loss: 2.5404\n",
            "Epoch: 5/10... Step: 500... Loss: 2.4863... Val Loss: 2.4463\n",
            "Epoch: 6/10... Step: 600... Loss: 2.3558... Val Loss: 2.3681\n",
            "Epoch: 7/10... Step: 700... Loss: 2.3140... Val Loss: 2.3018\n",
            "Epoch: 8/10... Step: 800... Loss: 2.2858... Val Loss: 2.2451\n",
            "Epoch: 9/10... Step: 900... Loss: 2.2377... Val Loss: 2.1992\n",
            "Epoch: 9/10... Step: 1000... Loss: 2.1404... Val Loss: 2.1516\n",
            "Epoch: 10/10... Step: 1100... Loss: 2.1328... Val Loss: 2.1119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_name = 'wikipediaperRnn.net'\n",
        "checkpoint = {'n_hidden': net.n_hidden,\n",
        "              'n_layers': net.n_layers,\n",
        "              'state_dict': net.state_dict(),\n",
        "              'tokens': net.chars}\n",
        "with open(model_name, 'wb') as f:\n",
        "    torch.save(checkpoint, f)"
      ],
      "metadata": {
        "id": "JwCTAUI_r2Gz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(net, char, h=None, top_k=None):\n",
        "        ''' Given a character, predict the next character.\n",
        "            Returns the predicted character and the hidden state.\n",
        "        '''\n",
        "       \n",
        "        x = np.array([[net.char2int[char]]])\n",
        "        x = one_hot_encode(x, len(net.chars))\n",
        "        inputs = torch.from_numpy(x)\n",
        "        \n",
        "        if(train_on_gpu):\n",
        "            inputs = inputs.cuda()\n",
        "        \n",
        " \n",
        "        h = tuple([each.data for each in h])\n",
        "   \n",
        "        out, h = net(inputs, h)\n",
        " \n",
        "        p = F.softmax(out, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            p = p.cpu()\n",
        "        \n",
        "    \n",
        "        if top_k is None:\n",
        "            top_ch = np.arange(len(net.chars))\n",
        "        else:\n",
        "            p, top_ch = p.topk(top_k)\n",
        "            top_ch = top_ch.numpy().squeeze()\n",
        "        \n",
        "  \n",
        "        p = p.numpy().squeeze()\n",
        "        char = np.random.choice(top_ch, p=p/p.sum())\n",
        "        \n",
        "     \n",
        "        return net.int2char[char], h\n",
        "def sample(net, size, prime='The', top_k=None):\n",
        "        \n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    else:\n",
        "        net.cpu()\n",
        "    \n",
        "    net.eval() \n",
        "    \n",
        "\n",
        "    chars = [ch for ch in prime]\n",
        "    h = net.init_hidden(1)\n",
        "    for ch in prime:\n",
        "        char, h = predict(net, ch, h, top_k=top_k)\n",
        "    chars.append(char)\n",
        "    \n",
        "   \n",
        "    for ii in range(size):\n",
        "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
        "        chars.append(char)\n",
        "    return ''.join(chars)"
      ],
      "metadata": {
        "id": "sS_vu4qFr2JY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(net, 500, prime='مهندسی مکانیک نخست در طی ', top_k=2))"
      ],
      "metadata": {
        "id": "lVLlnbc_r2K-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafd13ea-869b-43c6-cf51-ad68df57d354"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مهندسی مکانیک نخست در طی سال ۱۹۰۰ به در این مورد می شود.\n",
            "\n",
            "\n",
            "این است که در این این میانه است که این این استان می کند و به این این می شدند. در استان می شود.\n",
            "\n",
            "\n",
            "در ایر این این می شدند. است. است که این استان می کند. در سال ۱۹۰۰ بر می شود و این استان به دورهٔ می شود.\n",
            "\n",
            "\n",
            "از این اینشتین، این می کند که در است که این این مورد ایران با از این می کند که داران از موان به دول این میان با این این استان بازد.\n",
            "\n",
            "\n",
            "این میان به دولت استان می شود که در اینشانه ای از این این مورد می شود. داران از انتام مارد از این است که در سال ۱۹۰۰ مالی با با ا\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GB4YkAnnZyZA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}